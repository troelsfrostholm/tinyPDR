<HTML>
<HEAD>
   <TITLE> module L1_regression_module (generated by f90doc) </TITLE>
</HEAD>
<H1> Module L1_regression_module </H1>
<PRE>module L1_regression_module

        ! Types
    private type <A HREF="l1_regression_module.html#type_grschmidttype">GrSchmidtType</A>

        ! Variables
    integer, public, parameter :: <A HREF="l1_regression_module.html#var_realpara">realPara</A> = 8
    real (kind=realPara), public, parameter :: <A HREF="l1_regression_module.html#var_g_tolerance">g_tolerance</A> = 1.0E-8

        ! Subroutines and functions
    public subroutine <A HREF="l1_regression_module.html#subroutine_l1_regression">L1_regression</A> (i_x, i_y, o_a, o_b, o_f)
    private subroutine <A HREF="l1_regression_module.html#subroutine_regression_2d">regression_2D</A> (i_x, i_y, o_a, o_b, o_g, o_f, i_opt_step)
    private function <A HREF="l1_regression_module.html#function_grschmidtconstructorfn">GrSchmidtConstructorFn</A> (i_n) result (res)
    private subroutine <A HREF="l1_regression_module.html#subroutine_freespacegrschmidt">freeSpaceGrSchmidt</A> (c_x)
    private subroutine <A HREF="l1_regression_module.html#subroutine_addhyperplanegrschmidt">addHyperplaneGrSchmidt</A> (c_x, i_vect, i_x)
    private subroutine <A HREF="l1_regression_module.html#subroutine_updatehyperplanegrschmidt">updateHyperplaneGrSchmidt</A> (c_x, i_vect, i_x, i_objVect, o_isOptimal, o_reducedObjVect)
    private subroutine <A HREF="l1_regression_module.html#subroutine_releasehyperplifnottightgrschmidt">releaseHyperplIfNotTightGrSchmidt</A> (c_x, i_x)
    private subroutine <A HREF="l1_regression_module.html#subroutine_keeponlymaskedhyperplgrschmidt">keepOnlyMaskedHyperplGrSchmidt</A> (c_x, i_maske)
    private subroutine <A HREF="l1_regression_module.html#subroutine_removehyperplifktcoeffneggrschmidt">removeHyperplIfKTcoeffNegGrSchmidt</A> (c_x, i_objVect, o_opt_reducedObjVect, i_opt_iterativeRemove)
    private function <A HREF="l1_regression_module.html#function_calcgradient">calcGradient</A> (i_x, i_left, i_y) result (g)
    private subroutine <A HREF="l1_regression_module.html#subroutine_linesearch">lineSearch</A> (i_x, i_y, i_a, i_b, i_searchDirA, o_nextA, o_nextB, o_nextF)
    public pure function <A HREF="l1_regression_module.html#function_calcmedian2">calcMedian2</A> (i_x) result (res)
    private pure subroutine <A HREF="l1_regression_module.html#subroutine_real_sorting">real_sorting</A> (i_arr, o_perm)
    private elemental subroutine <A HREF="l1_regression_module.html#subroutine_swapping">swapping</A> (a, b)
    private pure function <A HREF="l1_regression_module.html#function_firstindxtrue">firstIndxTrue</A> (maske) result (res)
    private pure subroutine <A HREF="l1_regression_module.html#subroutine_getindxset3">getIndxSet3</A> (indxSet, maske)

end module L1_regression_module
</PRE>
 This module provides routine L1_regression, which
 calculates the L1-norm-regression coefficients to data points x(:,i),y(i).
<P>
 L1-norm regression is similar to the well known minimization of square-error
 regression, i.e. L2-norm regression.
 There are the following main differences between them:
 <UL>
 <LI>  1) L2-regression allows for a solution by solving a set of linear
      equations. i.e. It is easy and therefor the standard.
      L1-regression does not allow for such a simple solution.
      Instead a convex unconstraint minimization problem must be solved.
      The convex objective function is built up of hyperplane pieces.
 <LI>  2) L2-regression is unstable with respect to outliers, L1-regression is
      stable. That is why L1-regression is also called robust regression.
      The reason is that the solution of L2-regression is in some sense the
      mean of the slopes, whereas for L1-regression it is the median.
      When some points move outwards to become outliers it affects the mean
      but not the median.
<P>
 This software was written by Erich W. Steiner.
 It comes with NO warranty / guarantee. Everybody using it is responsible
 for the results himself. The author does not accept any liability for
 the results of this software or errors that maybe contained in the software.
 This software is provided as is under the 
 GNU-Lesser-Public-Licence. This note must not be removed.
 </UL>

<HR><H2> Description of Types </H2>
<A NAME="type_grschmidttype"><H3>GrSchmidtType</H3></A>
<PRE>private type GrSchmidtType
    integer :: n
</PRE>
<DL><DD><DL><DD>
 The present number of hyperplanes stored.
</DL></DL>
<PRE>    real (kind=realPara), dimension(:,:), allocatable :: Xs
</PRE>
<DL><DD><DL><DD>
 Stuetzvektoren
</DL></DL>
<PRE>    real (kind=realPara), dimension(:,:), allocatable :: V
</PRE>
<DL><DD><DL><DD>
 gradients of hyperplanes
</DL></DL>
<PRE>    real (kind=realPara), dimension(:,:), allocatable :: U
</PRE>
<DL><DD><DL><DD>
 Upper-triangular matrix.
</DL></DL>
<PRE>    real (kind=realPara), dimension(:,:), allocatable :: S
</PRE>
<DL><DD><DL><DD>
orthogonal Gr-Schmidt vectors.
</DL></DL>
<PRE>end type GrSchmidtType
</PRE>
 V*U=S  *=matmul.  Hyperplane i: (x-Xs(:,i)*V(:,i) = 0. *=dot_product.
 The components of GrSchmidtType are treated read-only in the code
 apart from those routine having GrSchmidt in their name which are
 intended to modify such an object.

<HR><H2> Description of Variables </H2>
<A NAME="var_realpara"><H3>realPara</H3></A>
<PRE>integer, public, parameter :: realPara = 8
</PRE>
 realPara is the kind-type for reals. 8 is usually double precision.
<A NAME="var_g_tolerance"><H3>g_tolerance</H3></A>
<PRE>real (kind=realPara), public, parameter :: g_tolerance = 1.0E-8
</PRE>
 g_tolerance defines a small positive number for considering
 values to be zero. Round-off tolerance. Set it to be roughly to
 square root of the precision of realPara real.

<HR><H2> Description of Subroutines and Functions </H2>
<A NAME="subroutine_l1_regression"><H3>L1_regression</H3></A>
<PRE>public subroutine L1_regression (i_x, i_y, o_a, o_b, o_f)
    real (kind=realPara), intent(in), dimension(:,:) :: i_x
    real (kind=realPara), intent(in), dimension(size(i_x, dim=2)) :: i_y
    real (kind=realPara), intent(out), dimension(size(i_x,dim=1)) :: o_a
    real (kind=realPara), intent(out) :: o_b
    real (kind=realPara), intent(out) :: o_f
    ! Calls: addHyperplaneGrSchmidt, freeSpaceGrSchmidt, lineSearch, releaseHyperplIfNotTightGrSchmidt, removeHyperplIfKTcoeffNegGrSchmidt
end subroutine L1_regression
</PRE>
 Routine calculates the linear regression for the points (i_x(:,i), i_y(i))
 minimizing the L1-norm. I.e the i-th column of i_x gives the x-coordinates
 of the i-th data point having y-value i_y(i). 
 The linear regression equation is:
<P>
 a*x + b = y     
<P>
 * meaning scalar dot_product. o_f is the minimal absolute deviation 
 between the approximated y and actual y values of the solution o_a, o_b.
<A NAME="subroutine_regression_2d"><H3>regression_2D</H3></A>
<PRE>private subroutine regression_2D (i_x, i_y, o_a, o_b, o_g, o_f, i_opt_step)
    real (kind=realPara), intent(in), dimension(:) :: i_x
    real (kind=realPara), intent(in), dimension(size(i_x)) :: i_y
    real (kind=realPara), intent(out), dimension(2) :: o_a
    real (kind=realPara), intent(out), dimension(2) :: o_b
    real (kind=realPara), intent(out), dimension(2) :: o_g
    real (kind=realPara), intent(out), dimension(2) :: o_f
    real (kind=realPara), optional, intent(in) :: i_opt_step
    ! Calls: checkForOptimality
end subroutine regression_2D
</PRE>
 Solves 2-dimensional L1-norm regression problem with bisection approach
 of minimizing the sum of absolute deviations.
 o_a(1), o_b(1) are the left solutions of the bisection with
 negative or = 0 gradient o_g(1) and sum of absolute deviations o_f(1),
 o_a(2), o_b(2), o_g(2), o_f(2) are the corresponding ones of the right
 bisection point solution with strictly positive gradient o_g(2).
 Stop when o_a(2)-o_a(1) <= g_tolerance or when o_g(1) < g_tolerance.
 The regression equation is:
<P>
 a*x + b = y.
<P>
 The used bisection incorporates binary bisection steps and 
 Newton-Raphson like subgradients intersection steps.
<A NAME="function_grschmidtconstructorfn"><H3>GrSchmidtConstructorFn</H3></A>
<PRE>private function GrSchmidtConstructorFn (i_n) result (res)
    integer, intent(in) :: i_n
    type (GrSchmidtType) :: res
end function GrSchmidtConstructorFn
</PRE>
 Allocates the components of res to n*n matrices and assigns 0 as values to them.
<A NAME="subroutine_freespacegrschmidt"><H3>freeSpaceGrSchmidt</H3></A>
<PRE>private subroutine freeSpaceGrSchmidt (c_x)
    type (GrSchmidtType), intent(inout) :: c_x
end subroutine freeSpaceGrSchmidt
</PRE>
 Deallocates the matrix components of c_x.
<A NAME="subroutine_addhyperplanegrschmidt"><H3>addHyperplaneGrSchmidt</H3></A>
<PRE>private subroutine addHyperplaneGrSchmidt (c_x, i_vect, i_x)
    type (GrSchmidtType), intent(inout) :: c_x
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_vect
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_x
end subroutine addHyperplaneGrSchmidt
</PRE>
 Adds the hyperplane  (x-i_x)*i_vect=0 to c_x. *=dot_product.
 If i_vect is linearly dependent to presently stored hyperplane normal vectors
 then i_vect, i_x is not added.
<A NAME="subroutine_updatehyperplanegrschmidt"><H3>updateHyperplaneGrSchmidt</H3></A>
<PRE>private subroutine updateHyperplaneGrSchmidt (c_x, i_vect, i_x, i_objVect, o_isOptimal, o_reducedObjVect)
    type (GrSchmidtType), intent(inout) :: c_x
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_vect
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_x
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_objVect
    logical, intent(out) :: o_isOptimal
    real (kind=realPara), intent(out), dimension(size(c_x%V,dim=1)) :: o_reducedObjVect
    ! Calls: addHyperplaneGrSchmidt, releaseHyperplIfNotTightGrSchmidt, removeHyperplIfKTcoeffNegGrSchmidt
end subroutine updateHyperplaneGrSchmidt
</PRE>
<A NAME="subroutine_releasehyperplifnottightgrschmidt"><H3>releaseHyperplIfNotTightGrSchmidt</H3></A>
<PRE>private subroutine releaseHyperplIfNotTightGrSchmidt (c_x, i_x)
    type (GrSchmidtType), intent(inout) :: c_x
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_x
    ! Calls: keepOnlyMaskedHyperplGrSchmidt
end subroutine releaseHyperplIfNotTightGrSchmidt
</PRE>
<A NAME="subroutine_keeponlymaskedhyperplgrschmidt"><H3>keepOnlyMaskedHyperplGrSchmidt</H3></A>
<PRE>private subroutine keepOnlyMaskedHyperplGrSchmidt (c_x, i_maske)
    type (GrSchmidtType), intent(inout) :: c_x
    logical, intent(in), dimension(:) :: i_maske
    ! Calls: addHyperplaneGrSchmidt, getIndxSet3
end subroutine keepOnlyMaskedHyperplGrSchmidt
</PRE>
<A NAME="subroutine_removehyperplifktcoeffneggrschmidt"><H3>removeHyperplIfKTcoeffNegGrSchmidt</H3></A>
<PRE>private subroutine removeHyperplIfKTcoeffNegGrSchmidt (c_x, i_objVect, o_opt_reducedObjVect, i_opt_iterativeRemove)
    type (GrSchmidtType), intent(inout) :: c_x
    real (kind=realPara), intent(in), dimension(size(c_x%V,dim=1)) :: i_objVect
    real (kind=realPara), optional, intent(out), dimension(size(c_x%V,dim=1)) :: o_opt_reducedObjVect
    logical, optional, intent(in) :: i_opt_iterativeRemove
    ! Calls: keepOnlyMaskedHyperplGrSchmidt
end subroutine removeHyperplIfKTcoeffNegGrSchmidt
</PRE>
 Removes those hyperplanes with negative KT-coefficient.
 If i_opt_iterativeRemove given and = true then does such remove
 steps iteratively until all KT-coefficients are positive.
<A NAME="function_calcgradient"><H3>calcGradient</H3></A>
<PRE>private function calcGradient (i_x, i_left, i_y) result (g)
    real (kind=realPara), intent(in), dimension(:,:) :: i_x
    real (kind=realPara), intent(in), dimension(size(i_x,dim=2)) :: i_left
    real (kind=realPara), intent(in), dimension(size(i_x,dim=2)) :: i_y
    real (kind=realPara), dimension(size(i_x,dim=1)) :: g
end function calcGradient
</PRE>
<A NAME="subroutine_linesearch"><H3>lineSearch</H3></A>
<PRE>private subroutine lineSearch (i_x, i_y, i_a, i_b, i_searchDirA, o_nextA, o_nextB, o_nextF)
    real (kind=realPara), intent(in), dimension(:,:) :: i_x
    real (kind=realPara), intent(in), dimension(size(i_x,dim=2)) :: i_y
    real (kind=realPara), intent(in), dimension(size(i_x,dim=1)) :: i_a
    real (kind=realPara), intent(in) :: i_b
    real (kind=realPara), intent(in), dimension(size(i_a)) :: i_searchDirA
    real (kind=realPara), intent(out), dimension(size(i_a),2) :: o_nextA
    real (kind=realPara), intent(out), dimension(2) :: o_nextB
    real (kind=realPara), intent(out), dimension(2) :: o_nextF
    ! Calls: regression_2D
end subroutine lineSearch
</PRE>
<A NAME="function_calcmedian2"><H3>calcMedian2</H3></A>
<PRE>public pure function calcMedian2 (i_x) result (res)
    real (kind=realPara), intent(in), dimension(:) :: i_x
    real (kind=realPara) :: res
    ! Calls: real_sorting
end function calcMedian2
</PRE>
 Let n=size(i_x). The function sorts i_x then returns sortedX(t) where
 t = (n+1)/2 if n is odd, or returns
 (sortedX(t) + sortedX(t+1)) / 2 where t=n/2 if n is even.
<A NAME="subroutine_real_sorting"><H3>real_sorting</H3></A>
<PRE>private pure subroutine real_sorting (i_arr, o_perm)
    real (kind=realPara), intent(in), dimension(:) :: i_arr
    integer, intent(out), dimension(:) :: o_perm
    ! Calls: swapping
end subroutine real_sorting
</PRE>
 Routine sorts i_arr such that i_arr(o_perm) is an increasing
 Array. Assumption: size(i_arr) = size(o_perm).
 Implements heap-sort. complexity n*log(n) with n=size(i_arr).
<A NAME="subroutine_swapping"><H3>swapping</H3></A>
<PRE>private elemental subroutine swapping (a, b)
    integer, intent(inout) :: a
    integer, intent(inout) :: b
end subroutine swapping
</PRE>
<A NAME="function_firstindxtrue"><H3>firstIndxTrue</H3></A>
<PRE>private pure function firstIndxTrue (maske) result (res)
    logical, intent(in), dimension(:) :: maske
    integer :: res
end function firstIndxTrue
</PRE>
 Routine gibt res zur�ck, so dass maske(res) = .true.
 und maske(i) = .false. f�r alle i < res.
 Wenn alle maske=.false. dann res = 0.
<A NAME="subroutine_getindxset3"><H3>getIndxSet3</H3></A>
<PRE>private pure subroutine getIndxSet3 (indxSet, maske)
    integer, intent(out), allocatable, dimension(:) :: indxSet
    logical, intent(in), dimension(:) :: maske
end subroutine getIndxSet3
</PRE>
 Routine alloziert indxSet und definiert indxSet, so dass
 maske(indxSet)==.true., indxSet maximal ist, indxSet der Groesse
 nach geordnet ist mit dem kleinsten Element vorne, kein Element
 in indxSet mehr als einmal vorkommt.
</HTML>
